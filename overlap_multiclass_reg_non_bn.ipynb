{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ./00.install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                        2.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "import os\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow channels_first\n"
     ]
    }
   ],
   "source": [
    "# def set_keras_backend(backend):\n",
    "\n",
    "#     if K.backend() != backend:\n",
    "#         os.environ['KERAS_BACKEND'] = backend\n",
    "#         reload(K)\n",
    "#         assert K.backend() == backend\n",
    "\n",
    "# set_keras_backend(\"theano\")\n",
    "K.set_image_data_format('channels_first')\n",
    "print(K.backend(), K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 #128\n",
    "samples_per_epoch = 10\n",
    "num_classes = 5\n",
    "epochs = 40\n",
    "# class_names = [\"voip\", \"video\", \"file transfer\", \"chat\", \"browsing\"]\n",
    "class_names=[\"file_transfer\", \"other\"]\n",
    "# input hist dimensions\n",
    "height, width = 1500, 1500\n",
    "input_shape = (1, height, width)\n",
    "# MODEL_NAME = \"overlap_multiclass_reg_non_bn\"\n",
    "MODEL_NAME=\"file_transfer_detection\"\n",
    "\n",
    "PATH_PREFIX = \"/root/dev/FlowPic/datasets/file_transfer_vs_all_\"\n",
    "\n",
    "# PATH_PREFIX = \"D:/TS/Internet Traffic Classification/datasets/overlap_multiclass_reg/overlap_multiclass_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(652, 1, 1500, 1500) (652,)\n",
      "(73, 1, 1500, 1500) (73,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(PATH_PREFIX + \"reg_x_train.npy\")\n",
    "y_train_true = np.load(PATH_PREFIX + \"reg_y_train.npy\")\n",
    "x_val = np.load(PATH_PREFIX + \"reg_x_val.npy\")\n",
    "y_val_true = np.load(PATH_PREFIX + \"reg_y_val.npy\")\n",
    "\n",
    "print(x_train.shape, y_train_true.shape)\n",
    "print(x_val.shape, y_val_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(652, 1, 1500, 1500) (652,)\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def shuffle_data(x, y):\n",
    "    s = np.arange(x.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x = x[s]\n",
    "    y = y[s]\n",
    "    print (x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train_true = shuffle_data(x_train, y_train_true)\n",
    "\n",
    "print(y_train_true[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "(652, 5) (73, 5)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train_true, num_classes)\n",
    "y_val = to_categorical(y_val_true, num_classes)\n",
    "print(y_train[0:10])\n",
    "print (y_val[0:10])\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/eta/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1737380736.445441  829767 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 300, 300)\n",
      "(None, 10, 150, 150)\n",
      "(None, 20, 30, 30)\n",
      "(None, 20, 15, 15)\n",
      "(None, 4500)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 5)\n"
     ]
    }
   ],
   "source": [
    "# def precision(y_true, y_pred):\n",
    "#     \"\"\"Precision metric.\n",
    "\n",
    "#     Only computes a batch-wise average of precision.\n",
    "\n",
    "#     Computes the precision, a metric for multi-label classification of\n",
    "#     how many selected items are relevant.\n",
    "#     \"\"\"\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "# def recall(y_true, y_pred):\n",
    "#     \"\"\"Recall metric.\n",
    "\n",
    "#     Only computes a batch-wise average of recall.\n",
    "\n",
    "#     Computes the recall, a metric for multi-label classification of\n",
    "#     how many relevant items are selected.\n",
    "#     \"\"\"\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "# def f1_score(y_true, y_pred):\n",
    "#     prec = precision(y_true, y_pred)\n",
    "#     rec = recall(y_true, y_pred)\n",
    "#     return 2*((prec*rec)/(prec+rec))\n",
    "\n",
    "# def top_2_categorical_accuracy(y_true, y_pred):\n",
    "#     return top_k_categorical_accuracy(y_true, y_pred, k=2) \n",
    "\n",
    "# # from keras.layers.core import Activation\n",
    "# from keras.layers import Activation\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# # model.add(BatchNormalization(input_shape=input_shape, axis=-1, momentum=0.99, epsilon=0.001)) ############################\n",
    "# model.add(Conv2D(10, kernel_size=(10, 10),strides=5,padding=\"same\", input_shape=input_shape))\n",
    "# convout1 = Activation('relu')\n",
    "# model.add(convout1)\n",
    "# print(model.output_shape)\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# print(model.output_shape)\n",
    "# model.add(Conv2D(20, (10, 10),strides=5,padding=\"same\"))  #################################################\n",
    "# convout2 = Activation('relu')\n",
    "# model.add(convout2)\n",
    "# print(model.output_shape)\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# print(model.output_shape)\n",
    "# model.add(Flatten())\n",
    "# print(model.output_shape)\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# print(model.output_shape)\n",
    "# model.add(Dropout(0.5))\n",
    "# print(model.output_shape)\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "# print(model.output_shape)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top_2_categorical_accuracy, f1_score, precision, recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define nice_imshow and make_moasic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy.ma as ma\n",
    "\n",
    "def nice_imshow(ax, data, vmin=None, vmax=None, cmap=None, bar=True):\n",
    "    \"\"\"Wrapper around pl.imshow\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = cm.jet\n",
    "    if vmin is None:\n",
    "        vmin = data.min()\n",
    "    if vmax is None:\n",
    "        vmax = data.max()\n",
    "    divider = make_axes_locatable(ax)\n",
    "    im = ax.imshow(data, vmin=vmin, vmax=vmax, interpolation='nearest', cmap=cmap,origin='lower')\n",
    "    if bar:\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        pl.colorbar(im, cax=cax)\n",
    "\n",
    "def plotNNFilter2(data, nrows, ncols, layer_name, cmap=None, bar=True):\n",
    "    \"\"\"Wrapper around pl.subplot with color bar\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = \"gray\"\n",
    "    \n",
    "    fig, axes = pl.subplots(nrows, ncols,figsize=(5*ncols, 4*nrows))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        im = ax.imshow(data[:,:,i], interpolation=\"nearest\", cmap=cmap)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.025, hspace=0.05)\n",
    "    if bar:\n",
    "        fig.colorbar(im, ax=axes.ravel().tolist())\n",
    "    \n",
    "    pl.savefig(MODEL_NAME +  \"_plotNNFilter2_\" + layer_name, bbox_inches='tight', pad_inches=1)\n",
    "    pl.show()\n",
    "\n",
    "def plotNNFilter(data, nrows, ncols, layer_name, cmap=None, bar=True):\n",
    "    \"\"\"Wrapper around pl.subplot\"\"\"\n",
    "    if cmap is None:\n",
    "        cmap = \"gray\"\n",
    "    \n",
    "    pl.figure(figsize=(3*ncols, 3*nrows))\n",
    "    \n",
    "    for i in range(nrows*ncols):\n",
    "        pl.subplot(nrows, ncols, i+1)\n",
    "        pl.imshow(data[:,:,i], interpolation=\"nearest\", cmap=cmap)\n",
    "        pl.xticks([])\n",
    "        pl.yticks([])\n",
    "        pl.gca().invert_yaxis()\n",
    "    pl.subplots_adjust(wspace=0.025, hspace=0.05)\n",
    "    pl.savefig(MODEL_NAME +  \"_plotNNFilter_\" + layer_name, bbox_inches='tight', pad_inches=1)\n",
    "    pl.show()\n",
    "        \n",
    "def make_mosaic(imgs, nrows, ncols, border=1):\n",
    "    \"\"\"\n",
    "    Given a set of images with all the same shape, makes a\n",
    "    mosaic with nrows and ncols\n",
    "    \"\"\"\n",
    "    nimgs = imgs.shape[2]\n",
    "    imshape = imgs.shape[0:2]\n",
    "    \n",
    "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
    "                            ncols * imshape[1] + (ncols - 1) * border),\n",
    "                            dtype=np.float32)\n",
    "    \n",
    "    paddedh = imshape[0] + border\n",
    "    paddedw = imshape[1] + border\n",
    "    for i in range(nimgs):\n",
    "        row = int(np.floor(i / ncols))\n",
    "        col = i % ncols\n",
    "        \n",
    "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
    "               col * paddedw:col * paddedw + imshape[1]] = imgs[:,:,i]\n",
    "    return mosaic\n",
    "\n",
    "def mosaic_imshow(imgs, nrows, ncols, cmap=None, border=1, layer_name=\"convout\"):\n",
    "    pl.figure(figsize=(3*ncols, 3*nrows))\n",
    "#     pl.suptitle('convout2')\n",
    "    nice_imshow(pl.gca(), make_mosaic(imgs, nrows, ncols, border=border), cmap=cmap)\n",
    "    pl.savefig(MODEL_NAME +  \"_mosaic_imshow_\" + layer_name, bbox_inches='tight', pad_inches=1)\n",
    "    pl.show()\n",
    "\n",
    "pl.imshow(make_mosaic(np.random.random((10, 10, 9)), 3, 3, border=1))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Visualize the first layer of convolutions on an input image\n",
    "\n",
    "i = 35\n",
    "X = x_train[i][0]\n",
    "print(X)\n",
    "print(y_train_true[i])\n",
    "pl.figure(figsize=(15, 15))\n",
    "pl.title('input')\n",
    "nice_imshow(pl.gca(), np.squeeze(X), vmin=0, vmax=1, cmap=cm.binary)\n",
    "pl.savefig(MODEL_NAME +  \"_input\", bbox_inches='tight', pad_inches=1)\n",
    "pl.show()\n",
    "\n",
    "# # Visualize convolution result (after activation)\n",
    "# def get_layer_output(layer, input_img, layer_name):\n",
    "#     # Create a Keras function using tf.keras.backend\n",
    "#     convout_f = tf.keras.backend.function(model.inputs, [layer.output])\n",
    "    \n",
    "#     # Get the output of the layer\n",
    "#     C = convout_f([input_img])\n",
    "    \n",
    "#     # Process the output\n",
    "#     C = np.squeeze(C)\n",
    "#     print(layer_name + \" output shape : \", C.shape)\n",
    "#     C = np.transpose(C)\n",
    "#     C = np.swapaxes(C, 0, 1)\n",
    "#     print(layer_name + \" output shape : \", C.shape)\n",
    "    \n",
    "#     return C\n",
    "#     # convout_f = tf.keras.backend.function(model.inputs, [layer.output])\n",
    "    # C = convout_f([input_img])\n",
    "    # C = np.squeeze(C)\n",
    "    # print(layer_name + \" output shape : \", C.shape)\n",
    "    # C = np.transpose(C)\n",
    "    # C = np.swapaxes(C, 0, 1)\n",
    "    # print(layer_name + \" output shape : \", C.shape)\n",
    "    # return C\n",
    "    # convout_f = K.function(model.inputs, [layer.output])\n",
    "    # C = convout_f([input_img])\n",
    "    # C = np.squeeze(C)\n",
    "    # print(layer_name + \" output shape : \", C.shape)\n",
    "    # C = np.transpose(C)\n",
    "    # C = np.swapaxes(C,0,1)\n",
    "    # print(layer_name + \" output shape : \", C.shape)\n",
    "    # return C\n",
    "    \n",
    "\n",
    "# C1 = get_layer_output(convout1, x_train[i:i+1], layer_name=\"convout1_before\")\n",
    "# mosaic_imshow(C1, 2, 5, cmap=cm.binary, border=2, layer_name=\"convout1_before\")\n",
    "# plotNNFilter(C1, 2, 5, cmap=cm.binary, layer_name=\"convout1_before\")\n",
    "# plotNNFilter2(C1, 2, 5, cmap=cm.binary, layer_name=\"convout1_before\")\n",
    "\n",
    "# C2 = get_layer_output(convout2, x_train[i:i+1], layer_name=\"convout2_before\")\n",
    "# mosaic_imshow(C2, 4, 5, cmap=cm.binary, border=2, layer_name=\"convout2_before\")\n",
    "# plotNNFilter(C2, 4, 5, cmap=cm.binary, layer_name=\"convout2_before\")\n",
    "# plotNNFilter2(C2, 4, 5, cmap=cm.binary, layer_name=\"convout2_before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# Visualize weights\n",
    "W1 = model.layers[0].get_weights()[0]\n",
    "W1 = np.squeeze(W1)\n",
    "# W1 = np.asarray(W1)\n",
    "print(\"W1 shape : \", W1.shape)\n",
    "\n",
    "mosaic_imshow(W1, 2, 5, cmap=cm.binary, border=1, layer_name=\"conv1_weights_before\")\n",
    "plotNNFilter(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights_before\")\n",
    "plotNNFilter2(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights_before\")\n",
    "\n",
    "# Visualize weights\n",
    "W2 = model.layers[3].get_weights()[0][:,:,0,:]\n",
    "W2 = np.asarray(W2)\n",
    "print(\"W2 shape : \", W2.shape)\n",
    "\n",
    "mosaic_imshow(W2, 4, 5, cmap=cm.binary, border=1, layer_name=\"conv2_weights_before\")\n",
    "plotNNFilter(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights_before\")\n",
    "plotNNFilter2(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights_before\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# def f1_score(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "#     f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "#     return f1_val\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "    precision_val = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_val\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    recall_val = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_val\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 300, 300)\n",
      "(None, 10, 150, 150)\n",
      "(None, 20, 30, 30)\n",
      "(None, 20, 15, 15)\n",
      "(None, 4500)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Sequential' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39moutput_shape)\n\u001b[1;32m     30\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m1500\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput shape: \u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Sequential' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Activation\n",
    "model = Sequential()\n",
    "# model.add(BatchNormalization(input_shape=input_shape, axis=-1, momentum=0.99, epsilon=0.001)) ############################\n",
    "model.add(Conv2D(10, kernel_size=(10, 10),strides=5,padding=\"same\", input_shape=input_shape))\n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "print(model.output_shape)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "print(model.output_shape)\n",
    "model.add(Conv2D(20, (10, 10),strides=5,padding=\"same\"))  #################################################\n",
    "convout2 = Activation('relu')\n",
    "model.add(convout2)\n",
    "print(model.output_shape)\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "print(model.output_shape)\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(64, activation='relu'))\n",
    "print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(model.output_shape)\n",
    "X = torch.rand(size=(1, 1, 1500, 1500), dtype=torch.float32)\n",
    "for layer in model:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)\n",
    "    print(\"hello\")\n",
    "assert False\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top_2_categorical_accuracy, f1_score, precision, recall])\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=[\n",
    "        'accuracy', \n",
    "        # tf.keras.metrics.top_k_categorical_accuracy(k=2, name='top_2_accuracy'),\n",
    "        # f1_score, \n",
    "        # precision, \n",
    "        # recall\n",
    "    ]\n",
    ")\n",
    "# 设置回调函数\n",
    "MODEL_NAME = \"file_transfer_detection\"\n",
    "log_dir = \"./Graph\"\n",
    "suffix=\".weights.h5\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "checkpointer_loss = ModelCheckpoint(filepath=MODEL_NAME + '_loss' + suffix, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "checkpointer_acc = ModelCheckpoint(monitor='val_accuracy', filepath=MODEL_NAME + '_acc' + suffix, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 数据生成器\n",
    "def generator(features, labels, batch_size):\n",
    "    num_samples = len(features)\n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    " \n",
    "\n",
    "# 创建数据生成器\n",
    "batch_size = 128\n",
    "train_generator = generator(x_train, y_train, batch_size)\n",
    "val_generator = generator(x_val, y_val, batch_size)\n",
    "\n",
    "# 计算每个 epoch 的步数\n",
    "steps_per_epoch = len(x_train) // batch_size\n",
    "validation_steps = len(x_val) // batch_size\n",
    "\n",
    "# 训练模型\n",
    "epochs = 10\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard_callback, checkpointer_loss, checkpointer_acc],\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (short unsigned int) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[51], line 39\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (short unsigned int) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# 假设输入数据的形状和类别数\n",
    "# input_shape = (1, 1500, 1500)  # 示例输入形状 (通道, 高度, 宽度)\n",
    "num_classes = len(class_names)  # 示例类别数\n",
    "\n",
    "# 定义模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 第一层卷积\n",
    "            nn.Conv2d(in_channels=input_shape[0], out_channels=10, kernel_size=10, stride=5, padding=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # 第二层卷积\n",
    "            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=10, stride=5, padding=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 展平\n",
    "            nn.Flatten(),\n",
    "            # 全连接层\n",
    "            nn.Linear(20 * 7 * 7, 64),  # 假设输入形状为 (1, 28, 28)，经过卷积和池化后的形状为 (20, 7, 7)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层\n",
    "            nn.Linear(64, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 将数据转换为 PyTorch 张量\n",
    "train_dataset = TensorDataset(torch.tensor(x_train).to(device), torch.tensor(y_train).to(device))\n",
    "val_dataset = TensorDataset(torch.tensor(x_val).to(device), torch.tensor(y_val).to(device))\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=file_transfer_detection_loss.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tensorboard \u001b[38;5;241m=\u001b[39m TensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Graph\u001b[39m\u001b[38;5;124m'\u001b[39m, histogram_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  write_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,write_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=1, write_grads=True, write_graph=True,write_images=True, batch_size=batch_size)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m checkpointer_loss \u001b[38;5;241m=\u001b[39m \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_loss.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m checkpointer_acc \u001b[38;5;241m=\u001b[39m ModelCheckpoint(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, filepath\u001b[38;5;241m=\u001b[39m MODEL_NAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_acc.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m tensorboard\u001b[38;5;241m.\u001b[39mset_model(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/eta/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:184\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_weights_only:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `save_weights_only=True` in `ModelCheckpoint`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the filepath provided must end in `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras weights format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(ext) \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m     ):\n",
      "\u001b[0;31mValueError\u001b[0m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=file_transfer_detection_loss.hdf5"
     ]
    }
   ],
   "source": [
    "# tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=1,  write_graph=True,write_images=True)\n",
    "# # tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=1, write_grads=True, write_graph=True,write_images=True, batch_size=batch_size)\n",
    "# checkpointer_loss = ModelCheckpoint(filepath= MODEL_NAME + '_loss.hdf5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# checkpointer_acc = ModelCheckpoint(monitor='val_acc', filepath= MODEL_NAME + '_acc.hdf5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# tensorboard.set_model(model)\n",
    "\n",
    "# def generator(features, labels, batch_size):\n",
    "#     index = 0\n",
    "#     while True:\n",
    "#         index += batch_size\n",
    "#         if index >= len(features):\n",
    "#             batch_features = np.append(features[index-batch_size:len(features)], features[0:index-len(features)], axis=0)\n",
    "#             batch_labels = np.append(labels[index-batch_size:len(features)], labels[0:index-len(features)], axis=0)\n",
    "#             index -= len(features)\n",
    "#             yield batch_features, batch_labels\n",
    "#         else:\n",
    "#             yield features[index-batch_size:index], labels[index-batch_size:index]\n",
    "\n",
    "# history = model.fit_generator(generator(x_train, y_train, batch_size),\n",
    "#           epochs=epochs,\n",
    "#           samples_per_epoch=samples_per_epoch,\n",
    "#           verbose=1,\n",
    "#           callbacks=[tensorboard,checkpointer_loss,checkpointer_acc],\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot history accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "with open(MODEL_NAME +  \"_accuracy.pkl\", 'wb') as output:\n",
    "    pickle.dump(history.history, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "x = np.asarray(range(1,epochs + 1))\n",
    "# summarize history for accuracy\n",
    "plt.figure()\n",
    "plt.plot(x, history.history['acc'])\n",
    "plt.plot(x, history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(MODEL_NAME +  \" accuracy history\", bbox_inches='tight', pad_inches=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "y_val_prediction = model.predict_classes(x_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "print(y_val_prediction[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          fname='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, format(cm[i, j]*100, fmt) + '%',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")    \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(fname, bbox_inches='tight', pad_inches=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_val_true, y_val_prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization',\n",
    "                      fname=MODEL_NAME + \"_\" + 'Confusion_matrix_without_normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix',\n",
    "                      fname=MODEL_NAME + \"_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "def stats(y_true, y_pred):\n",
    "    correct = sum([1 for i,pred in enumerate(y_pred) if y_true[i][pred]==1])\n",
    "    print(y_true.shape[0], correct, correct*1.0/len(y_true))\n",
    "    \n",
    "    for class_ind in range(y_true.shape[1]):\n",
    "        total_ind = len([1 for val in y_true if val[class_ind]==1])\n",
    "        correct_ind = sum([1 for i,pred in enumerate(y_pred) if (pred == class_ind and y_true[i][pred]==1)])\n",
    "        print(class_ind, total_ind, correct_ind, correct_ind*1.0/total_ind)\n",
    "\n",
    "stats(y_val, y_val_prediction)\n",
    "# stats(y_test_vpn, y_test_vpn_prediction)\n",
    "# stats(y_test_tor, y_test_tor_prediction)\n",
    "# correct_1 = sum([1 for i,pred in enumerate(y_test_prediction) if (pred == 1 and y_test[i][pred]==1)])\n",
    "# print correct_1, correct_1*1.0/len([1 for val in y_test if val[1]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val_true, y_val_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# # Visualize the first layer of convolutions on an input image\n",
    "# X = x_train[i][0]\n",
    "# print(X)\n",
    "# print(y_train_true[i])\n",
    "# pl.figure(figsize=(15, 15))\n",
    "# nice_imshow(pl.gca(), np.squeeze(X), vmin=0, vmax=1, cmap=cm.binary)\n",
    "# pl.savefig(MODEL_NAME +  \"_input_\" + str(int(y_train_true[i])), bbox_inches='tight', pad_inches=1)\n",
    "# pl.show()\n",
    "\n",
    "# # Visualize convolution result (after activation)\n",
    "# def get_layer_output(layer, input_img, layer_name):\n",
    "#     convout_f = K.function(model.inputs, [layer.output])\n",
    "#     C = convout_f([input_img])\n",
    "#     C = np.squeeze(C)\n",
    "#     print(layer_name + \" output shape : \", C.shape)\n",
    "#     C = np.transpose(C)\n",
    "#     C = np.swapaxes(C,0,1)\n",
    "#     print(layer_name + \" output shape : \", C.shape)\n",
    "#     return C\n",
    "\n",
    "\n",
    "# C1 = get_layer_output(convout1, x_train[i:i+1], layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "# mosaic_imshow(C1, 2, 5, cmap=cm.binary, border=2, layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "# plotNNFilter(C1, 2, 5, cmap=cm.binary, layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "# plotNNFilter2(C1, 2, 5, cmap=cm.binary, layer_name=\"convout1_\" + str(int(y_train_true[i])))\n",
    "\n",
    "# C2 = get_layer_output(convout2, x_train[i:i+1], layer_name=\"convout2_\" + str(int(y_train_true[i])))\n",
    "# mosaic_imshow(C2, 4, 5, cmap=cm.binary, border=2, layer_name=\"convout2_\" + str(int(y_train_true[i])))\n",
    "# plotNNFilter(C2, 4, 5, cmap=cm.binary, layer_name=\"convout2_\" + str(int(y_train_true[i])))\n",
    "# plotNNFilter2(C2, 4, 5, cmap=cm.binary, layer_name=\"convout2_\" + str(int(y_train_true[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# Visualize weights\n",
    "W1 = model.layers[0].get_weights()[0]\n",
    "W1 = np.squeeze(W1)\n",
    "# W1 = np.asarray(W1)\n",
    "print(\"W1 shape : \", W1.shape)\n",
    "\n",
    "mosaic_imshow(W1, 2, 5, cmap=cm.binary, border=1, layer_name=\"conv1_weights\")\n",
    "plotNNFilter(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights\")\n",
    "plotNNFilter2(W1, 2, 5, cmap=cm.binary, layer_name=\"conv1_weights\")\n",
    "\n",
    "# Visualize weights\n",
    "W2 = model.layers[3].get_weights()[0][:,:,0,:]\n",
    "W2 = np.asarray(W2)\n",
    "print(\"W2 shape : \", W2.shape)\n",
    "\n",
    "mosaic_imshow(W2, 4, 5, cmap=cm.binary, border=1, layer_name=\"conv2_weights\")\n",
    "plotNNFilter(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights\")\n",
    "plotNNFilter2(W2, 4, 5, cmap=cm.binary, layer_name=\"conv2_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "y_val_true, y_val_prediction\n",
    "\n",
    "for j in range(len(y_val_true)):\n",
    "    if y_val_true[j] == 0 and y_val_prediction[j] == 1:\n",
    "        print(j, sum(sum(sum(x_val[j]))))\n",
    "#         pl.figure(figsize=(10, 10))\n",
    "#         pl.title('input ' + str(j))\n",
    "#         nice_imshow(pl.gca(), np.squeeze(x_val[j]), vmin=0, vmax=1, cmap=cm.binary)\n",
    "#         pl.savefig(MODEL_NAME +  \"_input\", bbox_inches='tight', pad_inches=1)\n",
    "#         pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "x_test_vpn = np.load(PATH_PREFIX + \"vpn_x_test.npy\")\n",
    "y_test_vpn_true = np.load(PATH_PREFIX + \"vpn_y_test.npy\")\n",
    "x_test_tor = np.load(PATH_PREFIX + \"tor_x_test.npy\")\n",
    "y_test_tor_true = np.load(PATH_PREFIX + \"tor_y_test.npy\")\n",
    "\n",
    "y_test_vpn = to_categorical(y_test_vpn_true, num_classes)\n",
    "y_test_tor = to_categorical(y_test_tor_true, num_classes)\n",
    "\n",
    "print(x_test_vpn.shape, y_test_vpn.shape)\n",
    "print(x_test_tor.shape, y_test_tor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# model.load_weights(MODEL_NAME + '.hdf5')\n",
    "\n",
    "score_val = model.evaluate(x_val, y_val, verbose=1)\n",
    "print('Validation loss:', score_val[0])\n",
    "print('Validaion accuracy:', score_val[1])\n",
    "print('Validaion top_2_categorical_accuracy:', score_val[2])\n",
    "\n",
    "score_vpn = model.evaluate(x_test_vpn, y_test_vpn, verbose=1)\n",
    "print('VPN_Test loss:', score_vpn[0])\n",
    "print('VPN_Test accuracy:', score_vpn[1])\n",
    "print('VPN_Test top_2_categorical_accuracy:', score_vpn[2])\n",
    "\n",
    "score_tor = model.evaluate(x_test_tor, y_test_tor, verbose=1)\n",
    "print('TOR_Test loss:', score_tor[0])\n",
    "print('TOR_Test accuracy:', score_tor[1])\n",
    "print('TOR_Test top_2_categorical_accuracy:', score_tor[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "y_test_vpn_prediction = model.predict_classes(x_test_vpn, verbose=1)\n",
    "y_test_tor_prediction = model.predict_classes(x_test_tor, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "cnf_matrix_val = confusion_matrix(y_val_true, y_val_prediction)\n",
    "cnf_matrix_vpn = confusion_matrix(y_test_vpn_true, y_test_vpn_prediction)\n",
    "cnf_matrix_tor = confusion_matrix(y_test_tor_true, y_test_tor_prediction)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_val, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix for regular validation set',\n",
    "                      fname=MODEL_NAME + \"_val_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_vpn, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix for vpn test set',\n",
    "                      fname=MODEL_NAME + \"_test_vpn_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_tor, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix for tor test set',\n",
    "                      fname=MODEL_NAME + \"_test_tor_\" + 'Normalized_confusion_matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核已终止。错误: /root/miniconda3/bin/python: No module named ipykernel_launcher...有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(MODEL_NAME + '.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(MODEL_NAME + '.h5')\n",
    "print(\"Save Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
